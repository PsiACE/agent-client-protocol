---
title: "Prompt Turn"
description: "Understanding the conversation flow between Client and Agent"
---

A prompt turn represents a complete interaction cycle between the [Client](./overview#client) and [Agent](./overview#agent), starting with a user message and continuing until the Agent completes its response. This may involve multiple exchanges with the language model and tool invocations.

Before sending prompts, Clients **MUST** first complete the [initialization](./initialization) phase and [session setup](./session-setup).

## The Prompt Turn Lifecycle

A prompt turn follows a structured flow that enables rich interactions between the user, Agent, and any connected tools:

### 1. User Message

The turn begins when the Client sends a `session/prompt` request containing the user's message:

```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "session/prompt",
  "params": {
    "sessionId": "sess_abc123def456",
    "prompt": [
      {
        "type": "text",
        "text": "Can you analyze this code for potential issues?"
      },
      {
        "type": "embedded_resource",
        "resource": {
          "uri": "file:///home/user/project/main.py",
          "mimeType": "text/x-python",
          "content": "def process_data(items):\n    for item in items:\n        print(item)"
        }
      }
    ]
  }
}
```

This message **MAY** include various types of [content](./content) including text, images, audio, references to external resources, and embedded context.

{/* todo! move prompt capabilities to this page */}
Clients **MUST** only include types of content supported by the Agent according to its [Prompt Capabilities](./initialization#prompt-capabilities).

### 2. Agent Processing

Upon receiving the prompt request, the Agent processes the user's message and sends it to the language model, which **MAY** respond with text content, tool calls, or both.

### 3. Agent Reports Output

The Agent reports the model's output to the Client via `session/update` notifications:

```json
{
  "jsonrpc": "2.0",
  "method": "session/update",
  "params": {
    "sessionId": "sess_abc123def456",
    "update": {
      "sessionUpdate": "agent_message_chunk",
      "content": {
        "type": "text",
        "text": "I'll analyze your code for potential issues. Let me examine it..."
      }
    }
  }
}
```

If the model requested tool calls, these are also reported:

```json
{
  "jsonrpc": "2.0",
  "method": "session/update",
  "params": {
    "sessionId": "sess_abc123def456",
    "update": {
      "sessionUpdate": "tool_call",
      "id": "call_001",
      "name": "analyze_code",
      "arguments": {
        "code": "def process_data(items):\n    for item in items:\n        print(item)",
        "language": "python"
      }
    }
  }
}
```

### 4. Check for Completion

If there are no pending tool calls, the turn ends and the Agent **MUST** respond to the original `session/prompt` request with a `StopReason`:

```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "stopReason": "end_turn"
  }
}
```

Agents **MAY** stop the turn at any point by returning the corresponding [`StopReason`](#stop-reasons).

### 5. Tool Invocation and Status Reporting

If tool calls were requested, the Agent invokes each tool and reports their execution status to the Client via `session/update` notifications.
```json
{
  "jsonrpc": "2.0",
  "method": "session/update",
  "params": {
    "sessionId": "sess_abc123def456",
    "update": {
      "sessionUpdate": "tool_call_update",
      "id": "call_001",
      "status": "success",
      "output": "Analysis complete:\n- No syntax errors found\n- Consider adding type hints for better clarity\n- The function could benefit from error handling for empty lists"
    }
  }
}
```

The Agent **MAY** send updates as the tool runs, providing real-time feedback about tool execution progress.

### 6. Continue Conversation

The Agent sends the tool results back to the language model as another request.

The cycle returns to [step 2](#2-agent-processing), continuing until the language model completes its response without requesting additional tool calls or the turn gets stopped by the Agent or cancelled by the Client.

## Stop reasons

When an Agent stops a turn, it must specify the corresponding `StopReason`:

- `end_turn`: The language model finishes responding without requesting more tools
- `max_tokens`: The maximum token limit is reached
- `max_turn_requests`: The maximum number of model requests in a single turn is exceeded
- `refusal`: The Agent refuses to continue
- `cancelled`: The Client cancels the turn

---

Once a prompt turn completes, the Client may send another `session/prompt` to continue the conversation, building on the context established in previous turns.
